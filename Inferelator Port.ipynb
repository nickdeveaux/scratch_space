{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferelator.R ported to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas\n",
    "from scipy.stats import nbinom\n",
    "import seaborn\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proc_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-06-19\n"
     ]
    }
   ],
   "source": [
    "print proc_time.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PARS['input.dir'] = 'input/bsubtilis'\n",
    "PARS['exp.mat.file'] = 'expression.tsv'\n",
    "PARS['tf.names.file'] = 'tf_names.tsv'\n",
    "PARS['meta.data.file'] = 'meta_data.tsv'\n",
    "PARS['priors.file'] = None # 'gold_standard.tsv'\n",
    "PARS['gold.standard.file'] = 'gold_standard.tsv'\n",
    "PARS['leave.out.file'] = None\n",
    "PARS['randomize.expression'] = False\n",
    "PARS['job.seed'] = 42  # set to None if a random seed should be used\n",
    "PARS['save.to.dir'] = None\n",
    "PARS['num.boots'] = 20\n",
    "PARS['max.preds'] = 10\n",
    "PARS['mi.bins'] = 10\n",
    "PARS['cores'] = 8\n",
    "PARS['delT.max'] = 110\n",
    "PARS['delT.min'] = 0\n",
    "PARS['tau'] = 45\n",
    "\n",
    "# I've modified these parameters to make them lists\n",
    "PARS['perc.tp'] = [0]\n",
    "PARS['perm.tp'] = [1]\n",
    "PARS['perc.fp'] = [0]\n",
    "PARS['perm.fp'] = [1]\n",
    "PARS['pr.sel.mode'] = 'random'  # prior selection mode: 'random' or 'tf'\n",
    "PARS['eval.on.subset'] = False\n",
    "PARS['method'] = 'BBSR'  # 'BBSR' or 'MEN'\n",
    "PARS['prior.weight'] = 1\n",
    "PARS['use.tfa'] = False\n",
    "PARS['prior.ss'] = False\n",
    "PARS['output.summary'] = False\n",
    "PARS['output.report'] = False\n",
    "PARS['output.tf.plots'] = False\n",
    "# so['e of the elastic net parameters that are essentially constants;\n",
    "# on['y override in config script if you know what you are doing\n",
    "PARS['enet.sparseModels'] = True    # sparser models\n",
    "PARS['enet.nCv'] = 10               # number of cross-validations\n",
    "PARS['enet.lambda'] = [0, 1, 100]  # l2 weights\n",
    "PARS['enet.verbose'] = False        # print progress to screen\n",
    "PARS['enet.plot.it'] = False        # generate cross-validation plots\n",
    "PARS['enet.plot.file.name'] = None  # file name for plots\n",
    "PARS['method'] = 'BBSR'  # which method to use; either 'MEN' or 'BBSR'\n",
    "PARS['prior.weight'] = 1  # the weight for the priors; has to be larger than 1\n",
    "# fo[' priors to have an effect\n",
    "PARS['output.summary'] = True  # write a summary tsv and RData file of network\n",
    "PARS['output.report'] = True  # create html network report\n",
    "PARS['output.tf.plots'] = True  # create png files with plots of TFs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding variable to point to top level\n",
    "PARS['top.level.dir'] = '/Users/ndeveaux/Dev/Inferelator/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trivial_meta_data(column_names):\n",
    "    meta_data = pandas.DataFrame({'condName': column_names})\n",
    "    meta_data['isTs'] = False\n",
    "    meta_data['is1stLast'] = 'e'\n",
    "    meta_data['prevCol'] = None\n",
    "    meta_data['del.t'] = None\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I removed the read RData capability from read_input\n",
    "def read_input(input_dir, exp_mat_file, tf_names_file, meta_data_file, \n",
    "                       priors_file, gold_standard_file, leave_out_file, randomize_expression):\n",
    "  IN = {}\n",
    "  \n",
    "  print('Reading input: expression matrix')\n",
    "  IN['exp.mat'] = pandas.read_csv(os.path.join(input_dir, exp_mat_file), header=0, index_col=0, sep='\\t')\n",
    "  \n",
    "  print('Reading TF names')\n",
    "  IN['tf.names'] = list(set(pandas.read_csv(os.path.join(input_dir, tf_names_file), header=None, squeeze=True)))\n",
    "  \n",
    "  IN['tf.with.expr'] = intersect(IN['tf.names'], IN['exp.mat'].index)\n",
    "\n",
    "  print('reading metadata')\n",
    "  if meta_data_file: \n",
    "      IN['meta.data'] = pandas.read_csv(os.path.join(input_dir, meta_data_file), \n",
    "                                 header=0, sep='\\t')    \n",
    "  # no meta data given - assume all steady state measurements\n",
    "  else: \n",
    "      IN['meta.data'] = trivial_meta_data(IN['exp.mat'].columns)\n",
    "\n",
    "  \n",
    "  print('reading leave-out file')\n",
    "  # if there is a leave-out file, ignore some conditions\n",
    "  if leave_out_file:\n",
    "    leave_out = pandas.read_csv(os.path.join(input_dir, leave_out_file), header=None, squeeze=True)\n",
    "    print('Leaving out the following conditions: ' + leave_out)\n",
    "    print '{} of {} are present in the expression data'.format(\n",
    "        len(intersect(leave_out, list(IN['exp.mat'].columns))), len(leave_out))\n",
    "    # TODO implement leaveout\n",
    "  \n",
    "  \n",
    "  print('reading priors matrix')\n",
    "  IN['priors.mat'] = None\n",
    "  if priors_file:\n",
    "    IN['priors.mat'] = pandas.read_csv(os.path.join(input_dir, priors_file), header=0)\n",
    "    \n",
    "    # TODO write the reshape prior function (currently implement in R_scripts/utils.R)\n",
    "    # IN$priors.mat <- reshape.prior(IN$priors.mat, rownames(IN$exp.mat), IN$tf.names)\n",
    "  \n",
    "\n",
    "  print('reading gold standard matrix')\n",
    "  IN['gs.mat'] = None\n",
    "  if gold_standard_file:\n",
    "    IN['gs.mat'] = pandas.read_csv(os.path.join(input_dir, gold_standard_file),\n",
    "                                   header=0, sep='\\t')\n",
    "    # TODO write the reshape prior function (currently implement in R_scripts/utils.R)      \n",
    "    #IN$gs.mat <- reshape.prior(IN$gs.mat, rownames(IN$exp.mat), IN$tf.names)\n",
    "  \n",
    "  print(' ... done.')\n",
    "  \n",
    "  if randomize_expression:\n",
    "    print('randomize_expression is set to TRUE; randomizing expression matrix ...')\n",
    "    old_df = IN['exp.mat']\n",
    "    new_rows = np.random.permutation(IN['exp.mat'].shape[0])\n",
    "    new_cols = np.random.permutation(IN['exp.mat'].shape[1])\n",
    "    for row in range(IN['exp.mat'].shape[0]):\n",
    "        for col in range(IN['exp.mat'].shape[1]):\n",
    "            IN['exp.mat'].ix[row, col] = old_df.ix[new_rows[row], new_cols[col]]\n",
    "    print(' done.\\n')\n",
    "  \n",
    "  return IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # TODO: figure out if this is needed, if not, remove it\n",
    "    # create dummy clusterStack - a real clusterStack is only needed when inferring \n",
    "    # on bi-clusters\n",
    "   # clusterStack <- trivial.cluster.stack(IN$exp.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input: expression matrix\n",
      "Reading TF names\n",
      "reading metadata\n",
      "reading leave-out file\n",
      "reading priors matrix\n",
      "reading gold standard matrix\n",
      " ... done.\n"
     ]
    }
   ],
   "source": [
    "IN = read_input(os.path.join(PARS['top.level.dir'], PARS['input.dir']),PARS['exp.mat.file'], PARS['tf.names.file'], PARS['meta.data.file'], \n",
    "                       PARS['priors.file'], PARS['gold.standard.file'], PARS['leave.out.file'], PARS['randomize.expression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dir: /Users/ndeveaux/Dev/Inferelator/input/bsubtilis/2016-06-19\n"
     ]
    }
   ],
   "source": [
    "if not PARS['save.to.dir']:\n",
    "  PARS['save.to.dir'] = os.path.join(PARS['top.level.dir'], PARS['input.dir'],str(proc_time.date()))\n",
    "print \"Output dir: \" + PARS['save.to.dir']\n",
    "if not os.path.exists(PARS['save.to.dir']):\n",
    "  os.makedirs(PARS['save.to.dir'])\n",
    "elif os.path.exists(os.path.join(PARS['save.to.dir'], \"/params_and_input\")):\n",
    "  print 'The output file {} already exists. Exiting.'.format(os.path.join(PARS['save.to.dir'], \"/params_and_input\"))\n",
    "  # TODO find a way to Exit here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating design and response matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# design matrix is same as exp.mat leaving out last time points\n",
    "# response matrix is same as design for steady state; linear interpolation else\n",
    "def design_and_response(meta_data, exp_mat, delT_min, delT_max, tau):\n",
    "    cond = meta_data['condName']\n",
    "    prev = meta_data['prevCol']\n",
    "    delt = meta_data['del.t'] \n",
    "    \n",
    "    # the following operations (setting a value on a copy of a slice from a DataFrame) are not allowed with pandas\n",
    "    # break time series if del.t is larger than delT.max\n",
    "    # prev[delt > delT.max] <- NA\n",
    "    # delt[delt > delT.max] <- NA\n",
    "    \n",
    "    if set(meta_data['condName']) != set(exp_mat.columns):\n",
    "        print 'There are set differences between cond and exp mat'\n",
    "        \n",
    "        # Check that the condNames and the exp_mat columns are in sync:\n",
    "        mismatched_condNames = meta_data['condName'][meta_data['condName'] != exp_mat.columns]\n",
    "        \n",
    "        # This actually discovered a crucial difference between R data frames and pandas:\n",
    "        # R dataframes allow there to be two columns with the same name, but pandas won't \n",
    "        # Key example: Mt0_1 exists twice in expression data\n",
    "        if len(mismatched_condNames) > 0:\n",
    "            print \"There are rows in expression matrix that don't match metadata\"\n",
    "            print mismatched_condNames\n",
    "            correct_col_names = list(exp_mat.columns[meta_data['condName'] != exp_mat.columns])\n",
    "            print correct_col_names\n",
    "            # These can be set using the loc function:\n",
    "            meta_data['condName'][meta_data['condName'] != exp_mat.columns] = correct_col_names\n",
    "            \n",
    "        mismatched_condNames = meta_data['condName'][meta_data['condName'] != exp_mat.columns]\n",
    "        if len(mismatched_condNames) > 0:\n",
    "            print 'Rewrite Failed'\n",
    "    \n",
    "    if set(meta_data['condName']) != set(exp_mat.columns):\n",
    "        print 'There are still set differences between cond and exp mat'\n",
    "    else:\n",
    "        print 'All good'\n",
    "    \n",
    "    # Handle steady state conditions first\n",
    "    # Steady state is defined as not having a previous state, and not being any other state's previous state\n",
    "    steady = prev.isnull() & (cond.isin(prev) != True)\n",
    "    \n",
    "    # This is a quick fix but should instead use the prev col. \n",
    "    des_matrix = pandas.concat([pandas.DataFrame(exp_mat[cond[steady]]), pandas.DataFrame(exp_mat[cond[steady != True]])], axis = 1)\n",
    "    res_matrix = pandas.DataFrame(des_matrix)\n",
    "    \n",
    "    # This creates a 4218 row by  242 column matrix whose values are columns going from 1... 242\n",
    "    # resp.idx <- t(matrix(1:ncol(res.mat), ncol(res.mat), nrow(exp.mat)))\n",
    "    \n",
    "    # Having run the R code, the only difference I see in the des_matrix from exp_is the ordering. \n",
    "    return des_matrix, res_matrix\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call into R to get design and response matrices. \n",
    "# TODO: figure out why the existing exp_mat.csv is ok with having an offset top header col (seems like it should be fixed)\n",
    "# Additionally, why does it get chopped down to 136 conditions?\n",
    "IN['exp.mat'].to_csv('exp_mat.csv')\n",
    "IN['meta.data'].to_csv('meta_data.csv')\n",
    "subprocess.call(['R', '-f', './design_and_response_driver.R'])\n",
    "final_design = pandas.read_csv('design.tsv', sep='\\t')\n",
    "final_response = pandas.read_csv('response.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# des_matrix, res_matrix = design_and_response(IN['meta.data'], IN['exp.mat'], PARS['delT.min'], \n",
    "                               # PARS['delT.max'], PARS['tau'])\n",
    "des_matrix = final_design\n",
    "res_matrix = final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this function used to be important when we would iterate over the priors matrix and take samples/permutations\n",
    "# But all it does now is return the prior matrix\n",
    "def get_priors(exp_mat, tf_names, priors_mat, gs_mat, eval_on_subset, \n",
    "                      job_seed, perc_tp, perm_tp, perc_fp, perm_fp, sel_mode):\n",
    "    if priors_mat is None:\n",
    "        # Create a zero'd out DataFrame\n",
    "        priors_mat = pandas.DataFrame([[0 for x in range(len(tf_names))] for y in range(len(exp_mat.index))])\n",
    "        priors_mat.columns = tf_names\n",
    "        priors_mat.index = exp_mat.index\n",
    "        \n",
    "        \n",
    "    # priors.pars is list of prior parameters; every entry is a vector of four\n",
    "    # elements: perc.tp, tp permutation number, perc.fp, fp permutation number\n",
    "    priors_parameters = []\n",
    "    \n",
    "    # I tried to implement the length check but it seems silly in python since these aren't even vectors, they're scalars.\n",
    "    \n",
    "    lengths = [len(x) for x in [perc_tp, perm_tp, perc_fp, perm_fp]]\n",
    "    print lengths\n",
    "    if len(set(lengths)) != 1:\n",
    "        print \"\"\"Error parsing prior parameters: perc.tp, perm.tp, perc.fp, perm.fp \\\n",
    "        don't have the same length.\"\"\"\n",
    "        \n",
    "    for i in range(next(iter(set(lengths)))):\n",
    "        # Get the modulo remainder\n",
    "        rmndr = max(perm_tp[i], perm_fp[i]) % min(perm_tp[i], perm_fp[i])\n",
    "        if (rmndr != 0):\n",
    "            print\"\"\"Error parsing prior parameters: Larger number of permutations is \\\n",
    "            not multiple of smaller number.\"\"\"\n",
    "        priors_parameters.append([perc_tp, perm_tp, perc_fp, perm_fp])\n",
    "        \n",
    "    for pp in priors_parameters:\n",
    "        # priors[[i]] <- Matrix(0, nrow(priors.mat), ncol(priors.mat), dimnames=dimnames(priors.mat))\n",
    "        prior_names = 'frac_tp_{}_perm_{}--frac_fp_{}_perm_{}'.format(pp[0], pp[1], pp[2], pp[3])\n",
    "        \n",
    "    # Ignore the hundreds of lines of R code in priors.R\n",
    "    \n",
    "    return priors_mat, prior_names\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "priors_mat, prior_name = get_priors(IN['exp.mat'], IN['tf.names'], IN['priors.mat'], IN['gs.mat'], \n",
    "                       PARS['eval.on.subset'], PARS['job.seed'], PARS['perc.tp'],\n",
    "                       PARS['perm.tp'], PARS['perc.fp'], PARS['perm.fp'], \n",
    "                       PARS['pr.sel.mode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the bootstrap permutations\n",
    "# By sampling with replacement from the num cols of the result matrix\n",
    "col_range = range(len(res_matrix.columns))\n",
    "IN['bs.pi'] = pandas.DataFrame([[random.choice(col_range) for x in col_range] for y in range(PARS['num.boots'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>102</td>\n",
       "      <td>33</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>108</td>\n",
       "      <td>125</td>\n",
       "      <td>91</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>63</td>\n",
       "      <td>34</td>\n",
       "      <td>56</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>82</td>\n",
       "      <td>127</td>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>25</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>37</td>\n",
       "      <td>55</td>\n",
       "      <td>91</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>108</td>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109</td>\n",
       "      <td>67</td>\n",
       "      <td>113</td>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>48</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>98</td>\n",
       "      <td>103</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>55</td>\n",
       "      <td>83</td>\n",
       "      <td>18</td>\n",
       "      <td>122</td>\n",
       "      <td>109</td>\n",
       "      <td>104</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>65</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>78</td>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>123</td>\n",
       "      <td>12</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>114</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "      <td>90</td>\n",
       "      <td>104</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>128</td>\n",
       "      <td>13</td>\n",
       "      <td>119</td>\n",
       "      <td>129</td>\n",
       "      <td>63</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>77</td>\n",
       "      <td>48</td>\n",
       "      <td>111</td>\n",
       "      <td>129</td>\n",
       "      <td>65</td>\n",
       "      <td>124</td>\n",
       "      <td>60</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>104</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>76</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>96</td>\n",
       "      <td>123</td>\n",
       "      <td>92</td>\n",
       "      <td>30</td>\n",
       "      <td>98</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>42</td>\n",
       "      <td>105</td>\n",
       "      <td>124</td>\n",
       "      <td>119</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>105</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>104</td>\n",
       "      <td>89</td>\n",
       "      <td>48</td>\n",
       "      <td>110</td>\n",
       "      <td>91</td>\n",
       "      <td>96</td>\n",
       "      <td>108</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>59</td>\n",
       "      <td>114</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>93</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31</td>\n",
       "      <td>113</td>\n",
       "      <td>28</td>\n",
       "      <td>48</td>\n",
       "      <td>69</td>\n",
       "      <td>112</td>\n",
       "      <td>56</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>64</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>87</td>\n",
       "      <td>25</td>\n",
       "      <td>134</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>82</td>\n",
       "      <td>20</td>\n",
       "      <td>85</td>\n",
       "      <td>69</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>91</td>\n",
       "      <td>127</td>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>43</td>\n",
       "      <td>78</td>\n",
       "      <td>65</td>\n",
       "      <td>130</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>130</td>\n",
       "      <td>101</td>\n",
       "      <td>107</td>\n",
       "      <td>52</td>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>85</td>\n",
       "      <td>112</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>110</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>98</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>83</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "      <td>98</td>\n",
       "      <td>134</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>124</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>66</td>\n",
       "      <td>91</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>94</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>99</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>81</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>59</td>\n",
       "      <td>104</td>\n",
       "      <td>44</td>\n",
       "      <td>95</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>122</td>\n",
       "      <td>32</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>62</td>\n",
       "      <td>118</td>\n",
       "      <td>132</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>53</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>107</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>120</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>21</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>62</td>\n",
       "      <td>114</td>\n",
       "      <td>82</td>\n",
       "      <td>106</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>97</td>\n",
       "      <td>134</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>116</td>\n",
       "      <td>67</td>\n",
       "      <td>124</td>\n",
       "      <td>67</td>\n",
       "      <td>76</td>\n",
       "      <td>31</td>\n",
       "      <td>97</td>\n",
       "      <td>34</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "      <td>108</td>\n",
       "      <td>120</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>124</td>\n",
       "      <td>46</td>\n",
       "      <td>117</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>40</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>32</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>86</td>\n",
       "      <td>122</td>\n",
       "      <td>125</td>\n",
       "      <td>49</td>\n",
       "      <td>53</td>\n",
       "      <td>114</td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   126  127  128  129  \\\n",
       "0    65   87   46   48   17   38   60  102   33   87 ...    12  108  125   91   \n",
       "1    15  100  110    9  101  101   35    2   39   67 ...    50   82  127    9   \n",
       "2     7    0  126   37   55   91   34   20   61   73 ...   130   49   28  108   \n",
       "3   109   67  113  101    9   30    3  129   48   65 ...     4  109   52   31   \n",
       "4    15   79   55   83   18  122  109  104   45   10 ...    82   65   18   43   \n",
       "5    96   24  114   64   35   90  104   64   32   73 ...    28   18   33   17   \n",
       "6    16   53   77   48  111  129   65  124   60  114 ...    33   37   20   13   \n",
       "7    78   89    2  106   96  123   92   30   98  111 ...   101   42  105  124   \n",
       "8    71   13  104   89   48  110   91   96  108   86 ...    45   59  114   72   \n",
       "9    31  113   28   48   69  112   56   33    0    7 ...    41   48   44  100   \n",
       "10   45   75   70    8   18   87   25  134  122  120 ...    64    1   83   86   \n",
       "11   91  127   50   67   68   43   78   65  130  113 ...    30  130  101  107   \n",
       "12   95   98   70  110  104  109   98   65   20   32 ...   112   83   95  102   \n",
       "13   66   91   51   49   74   12   94   30   23   52 ...    25   99   58    8   \n",
       "14   81   20   17  125  126   59  104   44   95  135 ...    14   82   77   24   \n",
       "15    5   95   62  118  132   70   60  120   53   22 ...   110   27   67    5   \n",
       "16  107   65    6  129   64   73   85  120   38   32 ...    64   14   24   71   \n",
       "17   62  114   82  106   84   42   51   68   16   31 ...    53   97  134   85   \n",
       "18  116   67  124   67   76   31   97   34   87   51 ...    16   83  108  120   \n",
       "19   22  121   40   72   70   32  130  130    0   52 ...   122   86  122  125   \n",
       "\n",
       "    130  131  132  133  134  135  \n",
       "0    74   50   63   34   56  125  \n",
       "1    70   25   99    0   68  104  \n",
       "2    93   60   36   14   17   23  \n",
       "3    98  103   28   38   98    0  \n",
       "4    78   44   53  123   12  105  \n",
       "5   128   13  119  129   63   93  \n",
       "6   104   61   46   53   76  113  \n",
       "7   119   20   63   62  105   94  \n",
       "8    14   93   22   45   94    8  \n",
       "9    65   10   98   99   64   27  \n",
       "10    6   82   20   85   69  101  \n",
       "11   52   75   37   85  112   31  \n",
       "12   98  134   45   55  124   29  \n",
       "13   27  102    1   22   55   16  \n",
       "14   48  122   32  110    0   74  \n",
       "15   11  124   63   44   46   94  \n",
       "16   58   21  100   42   68    7  \n",
       "17   79   41   66    1  132   13  \n",
       "18   95   96  124   46  117   58  \n",
       "19   49   53  114   80   68  133  \n",
       "\n",
       "[20 rows x 136 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN['bs.pi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFA specific initialization\n",
    "Skipping for now, since use TFA set to false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "des_matrix = des_matrix.ix[ IN['tf.with.expr'] , :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas = []\n",
    "betas_resc  = []\n",
    "bins = PARS['mi.bins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(IN['bs.pi'])):\n",
    "    X = des_matrix.ix[:, IN['bs.pi'].ix[i,:]]\n",
    "    Y = res_matrix.ix[:, IN['bs.pi'].ix[i,:]]\n",
    "    X.to_csv('X.csv')\n",
    "    Y.to_csv('Y.csv')\n",
    "    priors_mat.to_csv('priors_mat.csv')\n",
    "    subprocess.call(['R', '-f', './mi_clr_driver.R'])\n",
    "    clr_matrix = pandas.read_csv('clr_matrix.tsv', sep='\\t')\n",
    "    clr_matrix = clr_matrix.ix[:, IN['tf.names']]\n",
    "    clr_matrix.to_csv('clr_matrix.csv')\n",
    "    subprocess.call(['R', '-f', './BBSR_driver.R'])\n",
    "    betas.append(pandas.read_csv('betas.tsv', sep='\\t'))\n",
    "    betas_resc.append(pandas.read_csv('betas_rescaled.tsv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Combine confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_confidences = pandas.DataFrame(np.zeros((betas[0].shape)), index = betas[0].index, columns = betas[0].columns )\n",
    "len(set(list(betas[9].columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for beta_resc in betas_resc:\n",
    "    # this ranking code is especially wordy because the rank function only works in one dimension (col or row), so I had to flatten the matrix\n",
    "    ranked_df =np.reshape(pandas.DataFrame(np.ndarray.flatten(beta_resc.values)).rank( method = \"average\").values, betas_resc[0].shape)\n",
    "    combined_confidences = combined_confidences + ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_element = min(combined_confidences.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_confidences = (combined_confidences - min_element) / (PARS['num.boots'] * combined_confidences.size - min_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99996705786926354"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(combined_confidences.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSU31410</th>\n",
       "      <th>BSU29740</th>\n",
       "      <th>BSU27890</th>\n",
       "      <th>BSU40800</th>\n",
       "      <th>BSU37650</th>\n",
       "      <th>BSU05370</th>\n",
       "      <th>BSU21780</th>\n",
       "      <th>BSU05700</th>\n",
       "      <th>BSU39430</th>\n",
       "      <th>BSU02970</th>\n",
       "      <th>...</th>\n",
       "      <th>BSU02370</th>\n",
       "      <th>BSU12560</th>\n",
       "      <th>BSU24020</th>\n",
       "      <th>BSU07220</th>\n",
       "      <th>BSU15320</th>\n",
       "      <th>BSU29400</th>\n",
       "      <th>BSU27170</th>\n",
       "      <th>BSU09520</th>\n",
       "      <th>BSU25490</th>\n",
       "      <th>BSU17850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSU00370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU08100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU01810</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU24250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU36020</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BSU31410  BSU29740  BSU27890  BSU40800  BSU37650  BSU05370  \\\n",
       "BSU00370       0.0  0.000000       0.0  0.049434       0.0       0.0   \n",
       "BSU08100       0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "BSU01810       0.0  0.049506       0.0  0.000000       0.0       0.0   \n",
       "BSU24250       0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "BSU36020       0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "\n",
       "          BSU21780  BSU05700  BSU39430  BSU02970    ...     BSU02370  \\\n",
       "BSU00370       0.0       0.0       0.0       0.0    ...     0.000000   \n",
       "BSU08100       0.0       0.0       0.0       0.0    ...     0.000000   \n",
       "BSU01810       0.0       0.0       0.0       0.0    ...     0.000000   \n",
       "BSU24250       0.0       0.0       0.0       0.0    ...     0.099597   \n",
       "BSU36020       0.0       0.0       0.0       0.0    ...     0.000000   \n",
       "\n",
       "          BSU12560  BSU24020  BSU07220  BSU15320  BSU29400  BSU27170  \\\n",
       "BSU00370       0.0  0.000000       0.0       0.0  0.049413       0.0   \n",
       "BSU08100       0.0  0.000000       0.0       0.0  0.000000       0.0   \n",
       "BSU01810       0.0  0.000000       0.0       0.0  0.000000       0.0   \n",
       "BSU24250       0.0  0.000000       0.0       0.0  0.099377       0.0   \n",
       "BSU36020       0.0  0.099615       0.0       0.0  0.149117       0.0   \n",
       "\n",
       "          BSU09520  BSU25490  BSU17850  \n",
       "BSU00370       0.0       0.0       0.0  \n",
       "BSU08100       0.0       0.0       0.0  \n",
       "BSU01810       0.0       0.0       0.0  \n",
       "BSU24250       0.0       0.0       0.0  \n",
       "BSU36020       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_confidences.to_csv('combined_confidences.csv')\n",
    "combined_confidences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold and Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "th = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_sign = pandas.DataFrame(np.zeros((betas[0].shape)), index = betas[0].index, columns = betas[0].columns )\n",
    "betas_non_zero = pandas.DataFrame(np.zeros((betas[0].shape)), index = betas[0].index, columns = betas[0].columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    1, ..., 4216, 4217, 4217]),\n",
       " array([124, 207,  58, ..., 216,  79, 101]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(betas[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for beta in betas:\n",
    "    betas_sign = betas_sign + np.sign(beta.values)\n",
    "    betas_non_zero = betas_non_zero + np.absolute(np.sign(beta.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we only care about interactions that are present in more than th (fraction) bootstraps\n",
    "ind_vec = np.where( betas_non_zero > len(betas) * th)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas_stack = np.stack([b.values[ind_vec] for b in betas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas_mean = np.mean(betas_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_median = np.median(betas_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_min = np.min(betas_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_max = np.max(betas_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas_resc_stack = np.stack([b.values[ind_vec] for b in betas_resc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas_resc_mean = np.mean(betas_resc_stack, axis = 0)\n",
    "betas_resc_median = np.median(betas_resc_stack, axis = 0)\n",
    "betas_resc_min = np.min(betas_resc_stack, axis = 0)\n",
    "betas_resc_max = np.max(betas_resc_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUPR calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates = np.where( combined_confidences > 0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For some reason there are more target genes in the gold standard than we've gotten from the exp matrix\n",
    "# Filter it\n",
    "gold_standard_filtered = IN['gs.mat'].loc[combined_confidences.index]\n",
    "gold_standard_filtered = gold_standard_filtered[combined_confidences.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "condition_positive = len(np.where(gold_standard_filtered.values > 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rank from highest to lowest confidence\n",
    "sorted_candidates = np.argsort(combined_confidences.values[candidates], axis = None)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99996705786926354"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_confidences.values[candidates][sorted_candidates[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_values = np.array(gold_standard_filtered.values[candidates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_values[sorted_candidates[0:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = 0.0\n",
    "FP = 0.0\n",
    "precision = []\n",
    "recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in sorted_candidates:\n",
    "    truth = gs_values[i]\n",
    "    if truth == 1:\n",
    "        TP = TP + 1\n",
    "    else:\n",
    "        FP = FP + 1\n",
    "    precision.append(TP / (TP + FP))\n",
    "    recall.append(TP / condition_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1196ef810>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFkCAYAAABW9YMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niFIQAwAREVEKYgAgIiJKQf8fkeTw7oxgbBEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b755c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recall, precision)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4218, 239)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_confidences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1004958\n",
       "1       3144\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.value_counts(np.ndarray.flatten(gold_standard_filtered.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSU31410</th>\n",
       "      <th>BSU29740</th>\n",
       "      <th>BSU27890</th>\n",
       "      <th>BSU40800</th>\n",
       "      <th>BSU37650</th>\n",
       "      <th>BSU05370</th>\n",
       "      <th>BSU21780</th>\n",
       "      <th>BSU05700</th>\n",
       "      <th>BSU39430</th>\n",
       "      <th>BSU02970</th>\n",
       "      <th>...</th>\n",
       "      <th>BSU02370</th>\n",
       "      <th>BSU12560</th>\n",
       "      <th>BSU24020</th>\n",
       "      <th>BSU07220</th>\n",
       "      <th>BSU15320</th>\n",
       "      <th>BSU29400</th>\n",
       "      <th>BSU27170</th>\n",
       "      <th>BSU09520</th>\n",
       "      <th>BSU25490</th>\n",
       "      <th>BSU17850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSU00370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU08100</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU01810</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU24250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU36020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BSU31410  BSU29740  BSU27890  BSU40800  BSU37650  BSU05370  \\\n",
       "BSU00370         0         0         0         0         0         0   \n",
       "BSU08100         0         1         0         0         0         0   \n",
       "BSU01810         0         0         0         0         0         0   \n",
       "BSU24250         0         0         0         0         0         0   \n",
       "BSU36020         0         0         0         0         0         0   \n",
       "\n",
       "          BSU21780  BSU05700  BSU39430  BSU02970    ...     BSU02370  \\\n",
       "BSU00370         0         0         0         0    ...            0   \n",
       "BSU08100         0         0         0         0    ...            0   \n",
       "BSU01810         0         0         0         0    ...            0   \n",
       "BSU24250         0         0         0         0    ...            0   \n",
       "BSU36020         0         0         0         0    ...            0   \n",
       "\n",
       "          BSU12560  BSU24020  BSU07220  BSU15320  BSU29400  BSU27170  \\\n",
       "BSU00370         0         0         0         0         0         0   \n",
       "BSU08100         0         0         0         0         0         0   \n",
       "BSU01810         0         0         0         0         0         0   \n",
       "BSU24250         0         0         0         0         0         0   \n",
       "BSU36020         0         0         0         0         0         0   \n",
       "\n",
       "          BSU09520  BSU25490  BSU17850  \n",
       "BSU00370         0         0         0  \n",
       "BSU08100         0         0         0  \n",
       "BSU01810         0         0         0  \n",
       "BSU24250         0         0         0  \n",
       "BSU36020         0         0         0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_standard_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    953195\n",
       "0.048867         9\n",
       "0.048881         7\n",
       "0.048856         7\n",
       "0.048896         7\n",
       "0.048926         7\n",
       "0.048898         7\n",
       "0.048893         6\n",
       "0.048911         6\n",
       "0.048861         6\n",
       "0.048923         6\n",
       "0.049029         6\n",
       "0.049245         6\n",
       "0.049111         6\n",
       "0.048869         6\n",
       "0.049143         6\n",
       "0.049079         6\n",
       "0.048894         6\n",
       "0.048861         6\n",
       "0.049003         6\n",
       "0.048960         6\n",
       "0.048913         6\n",
       "0.049121         6\n",
       "0.048899         6\n",
       "0.048940         6\n",
       "0.049076         6\n",
       "0.049033         6\n",
       "0.048976         6\n",
       "0.048935         6\n",
       "0.048929         6\n",
       "             ...  \n",
       "0.098868         1\n",
       "0.099018         1\n",
       "0.048955         1\n",
       "0.496351         1\n",
       "0.147369         1\n",
       "0.049012         1\n",
       "0.197110         1\n",
       "0.395373         1\n",
       "0.295650         1\n",
       "0.148451         1\n",
       "0.098184         1\n",
       "0.245114         1\n",
       "0.343397         1\n",
       "0.147629         1\n",
       "0.097924         1\n",
       "0.147269         1\n",
       "0.099166         1\n",
       "0.737655         1\n",
       "0.098595         1\n",
       "0.942309         1\n",
       "0.695251         1\n",
       "0.248608         1\n",
       "0.049714         1\n",
       "0.049378         1\n",
       "0.049609         1\n",
       "0.049354         1\n",
       "0.098755         1\n",
       "0.147479         1\n",
       "0.198156         1\n",
       "0.344010         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick way to double check distribution of values\n",
    "# pandas.value_counts(np.ndarray.flatten(combined_confidences.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3626.0785581996988"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(betas_resc[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "argsorted = np.argsort(betas_resc[1].values, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([670113, 670114, 670115, ..., 669183, 669184, 669185])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argsorted[1:3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step one of loop\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas.append(pandas.read_csv('betas.tsv', sep='\\t'))\n",
    "betas_resc.append(pandas.read_csv('betas_rescaled.tsv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set a random sample of the edges to zero\n",
    "# only need to do this if we have priors\n",
    "\n",
    "# group predictors just returns the design matrix, res and prior matrix if it finds no groups:\n",
    "# if no TF was excluded and no TFs were grouped, it returns the des, res, and prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_predictors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = des_matrix.ix[:, IN['bs.pi'].ix[i,:]]\n",
    "Y = res_matrix.ix[:, IN['bs.pi'].ix[i,:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder on mutual information:\n",
    "<img src=\"files/olah_mi.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Short example\n",
    "x = X.ix[200,:]\n",
    "y = Y.ix[200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H, xedges, yedges = np.histogram2d(x,y,bins)\n",
    "plt.set_cmap('viridis')\n",
    "im = plt.imshow(H, interpolation='none', \n",
    "                extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an inefficient implementation of calc_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shannon_entropy(p):\n",
    "    # Since p represents a discrete prob dist, check for floating point approximation to 1.0\n",
    "    if not np.allclose(sum(p), 1.0): \n",
    "        raise Exception('Probabilities input to shannon entropy need to sum to 1')\n",
    "    return - sum([x * np.log(x) for x in p if x != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_mi(x, y, bins):\n",
    "    hist, scale  = np.histogram(x, bins)\n",
    "    x_p = hist / float(sum(hist))\n",
    "    hist, scale = np.histogram(y, bins)\n",
    "    y_p = hist / float(sum(hist))\n",
    "    H, xscale, yscale = np.histogram2d(x ,y, bins)\n",
    "    joint_p = (H / float(sum(sum(H)))).flatten()\n",
    "    return (shannon_entropy(y_p) + shannon_entropy(x_p)) - shannon_entropy(joint_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFVCAYAAAA+OJwpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngAEEGQAAAwgyAAAGEGQAAAz4P4HTN88VsKfMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119f7a210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins = np.histogram(X.ix[10,:],bins)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25764680571550524"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mi(X.ix[100,:], Y.ix[100,:], PARS['mi.bins'])\n",
    "# mi_matrix = [[calc_mi(X.ix[i,:], Y.ix[j,:], PARS['mi.bins']) for i in range(X.shape[0])] for j in range(Y.shape[0])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(X.index) > 6000:\n",
    "    # speeds up MI calculation for large datasets\n",
    "    # I actually don't know what this does, since X's rows are already filtered by 'tf.with.expr', \n",
    "    # which itself if a subset of IN['tf.names']\n",
    "    X = X.ix[group_predictors['tf_names'], :] # This turn X into a TFs x Samples matrix, which is what I expected it to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist, scale  = np.histogram(x, bins)\n",
    "x_p = hist / float(sum(hist))\n",
    "hist, scale = np.histogram(y, bins)\n",
    "y_p = hist / float(sum(hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optionally investigate sklearn.metrics.mutual_info_score(x_p, x_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call into R to calculate tlCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('X.csv')\n",
    "Y.to_csv('Y.csv')\n",
    "priors_mat.to_csv('priors_mat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(['R', '--slave', '-f', './mi_clr_driver.R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clr_matrix = pandas.read_csv('clr_matrix.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter by tf names (this doesn't do anything in the case of B Subtilus, and should filter by group predictions)\n",
    "clr_matrix = clr_matrix.ix[:, IN['tf.names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clr_matrix.to_csv('clr_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(['R', '--slave', '-f', './BBSR_driver.R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSU31410</th>\n",
       "      <th>BSU29740</th>\n",
       "      <th>BSU27890</th>\n",
       "      <th>BSU40800</th>\n",
       "      <th>BSU37650</th>\n",
       "      <th>BSU05370</th>\n",
       "      <th>BSU21780</th>\n",
       "      <th>BSU05700</th>\n",
       "      <th>BSU39430</th>\n",
       "      <th>BSU02970</th>\n",
       "      <th>...</th>\n",
       "      <th>BSU02370</th>\n",
       "      <th>BSU12560</th>\n",
       "      <th>BSU24020</th>\n",
       "      <th>BSU07220</th>\n",
       "      <th>BSU15320</th>\n",
       "      <th>BSU29400</th>\n",
       "      <th>BSU27170</th>\n",
       "      <th>BSU09520</th>\n",
       "      <th>BSU25490</th>\n",
       "      <th>BSU17850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSU00370</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.331829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053941</td>\n",
       "      <td>0.546521</td>\n",
       "      <td>0.247536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474254</td>\n",
       "      <td>0.102544</td>\n",
       "      <td>0.287538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632939</td>\n",
       "      <td>1.041414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.074986</td>\n",
       "      <td>0.241752</td>\n",
       "      <td>0.064521</td>\n",
       "      <td>0.616567</td>\n",
       "      <td>0.130521</td>\n",
       "      <td>0.762131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU08100</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.581412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.918470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319477</td>\n",
       "      <td>0.844766</td>\n",
       "      <td>0.302097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.581768</td>\n",
       "      <td>1.259320</td>\n",
       "      <td>0.222817</td>\n",
       "      <td>0.237525</td>\n",
       "      <td>0.268205</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU01810</th>\n",
       "      <td>1.155553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.493640</td>\n",
       "      <td>0.152953</td>\n",
       "      <td>0.082841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443350</td>\n",
       "      <td>1.578638</td>\n",
       "      <td>1.188237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.253709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU24250</th>\n",
       "      <td>0.917109</td>\n",
       "      <td>2.060313</td>\n",
       "      <td>1.182781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.165756</td>\n",
       "      <td>0.970381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.788951</td>\n",
       "      <td>0.424076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.110401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.698148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017698</td>\n",
       "      <td>1.078584</td>\n",
       "      <td>3.825155</td>\n",
       "      <td>1.904571</td>\n",
       "      <td>0.706518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU36020</th>\n",
       "      <td>0.770376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.016767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458314</td>\n",
       "      <td>0.040748</td>\n",
       "      <td>1.104357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811787</td>\n",
       "      <td>0.290950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626139</td>\n",
       "      <td>1.087694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BSU31410  BSU29740  BSU27890  BSU40800  BSU37650  BSU05370  \\\n",
       "BSU00370  0.000000  1.331829  0.000000  0.053941  0.546521  0.247536   \n",
       "BSU08100  0.000000  0.000000  0.581412  0.000000  0.000000  0.000000   \n",
       "BSU01810  1.155553  0.000000  0.000000  1.493640  0.152953  0.082841   \n",
       "BSU24250  0.917109  2.060313  1.182781  0.000000  1.165756  0.970381   \n",
       "BSU36020  0.770376  0.000000  1.016767  0.000000  0.000000  0.000000   \n",
       "\n",
       "          BSU21780  BSU05700  BSU39430  BSU02970    ...     BSU02370  \\\n",
       "BSU00370       0.0  0.474254  0.102544  0.287538    ...     0.632939   \n",
       "BSU08100       0.0  0.000000  0.000000  0.918470    ...     0.319477   \n",
       "BSU01810       0.0  0.218325  0.000000  0.357855    ...     0.443350   \n",
       "BSU24250       0.0  1.788951  0.424076  0.000000    ...     2.110401   \n",
       "BSU36020       0.0  0.458314  0.040748  1.104357    ...     0.118278   \n",
       "\n",
       "          BSU12560  BSU24020  BSU07220  BSU15320  BSU29400  BSU27170  \\\n",
       "BSU00370  1.041414  0.000000  0.000000  1.074986  0.241752  0.064521   \n",
       "BSU08100  0.844766  0.302097  0.000000  1.581768  1.259320  0.222817   \n",
       "BSU01810  1.578638  1.188237  0.000000  1.253709  0.000000  0.000000   \n",
       "BSU24250  0.000000  0.000000  0.698148  0.000000  0.017698  1.078584   \n",
       "BSU36020  0.000000  0.000000  0.000000  0.000000  0.811787  0.290950   \n",
       "\n",
       "          BSU09520  BSU25490  BSU17850  \n",
       "BSU00370  0.616567  0.130521  0.762131  \n",
       "BSU08100  0.237525  0.268205  0.000000  \n",
       "BSU01810  0.043018  0.000000  0.309516  \n",
       "BSU24250  3.825155  1.904571  0.706518  \n",
       "BSU36020  0.000000  0.626139  1.087694  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_matrix.ix[:, IN['tf.names']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ignore priors for now: priors_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Enter BBSR\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  # Scale and permute design and response matrix\n",
    "X_scaled = pandas.DataFrame(preprocessing.scale(X, axis = 1), index = X.index, columns = X.columns)\n",
    "Y_scaled = pandas.DataFrame(preprocessing.scale(Y, axis = 1), index = Y.index, columns = Y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = Y.shape[0]  # number of genes\n",
    "genes = list(Y.index)\n",
    "K = X.shape[0]  # max number of possible predictors (number of TFs)\n",
    "tfs = list(X.index)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000004"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check that the scaling made each row's std deviations set to 1\n",
    "np.std(X_scaled.ix[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictors that will be used in the regression\n",
    "pp = pandas.DataFrame(np.zeros((G, K)), index = genes, columns = tfs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get top highest indices per row in clr_matrix, store as top_sorted object\n",
    "top_sorted = np.argsort(clr_matrix, axis = 1).ix[:, K - PARS['max.preds']: K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each gene, add the top nS predictors of the list to possible predictors\n",
    "for i in range(G):\n",
    "    pp.ix[i, top_sorted.ix[i, :]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    965922\n",
       "1.0     42180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this point, we expect the values of 1s to be equal to the number of Genes x PARS['max.preds'] (Which should be 10)\n",
    "pandas.value_counts(np.ndarray.flatten(pp.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSU31410</th>\n",
       "      <th>BSU29740</th>\n",
       "      <th>BSU27890</th>\n",
       "      <th>BSU40800</th>\n",
       "      <th>BSU37650</th>\n",
       "      <th>BSU05370</th>\n",
       "      <th>BSU21780</th>\n",
       "      <th>BSU05700</th>\n",
       "      <th>BSU39430</th>\n",
       "      <th>BSU02970</th>\n",
       "      <th>...</th>\n",
       "      <th>BSU02370</th>\n",
       "      <th>BSU12560</th>\n",
       "      <th>BSU24020</th>\n",
       "      <th>BSU07220</th>\n",
       "      <th>BSU15320</th>\n",
       "      <th>BSU29400</th>\n",
       "      <th>BSU27170</th>\n",
       "      <th>BSU09520</th>\n",
       "      <th>BSU25490</th>\n",
       "      <th>BSU17850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSU00370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU08100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU01810</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU24250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU36020</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BSU31410  BSU29740  BSU27890  BSU40800  BSU37650  BSU05370  \\\n",
       "BSU00370       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU08100       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU01810       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU24250       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU36020       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "          BSU21780  BSU05700  BSU39430  BSU02970    ...     BSU02370  \\\n",
       "BSU00370       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "BSU08100       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "BSU01810       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "BSU24250       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "BSU36020       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "\n",
       "          BSU12560  BSU24020  BSU07220  BSU15320  BSU29400  BSU27170  \\\n",
       "BSU00370       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU08100       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU01810       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU24250       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU36020       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "          BSU09520  BSU25490  BSU17850  \n",
       "BSU00370       0.0       0.0       0.0  \n",
       "BSU08100       0.0       0.0       0.0  \n",
       "BSU01810       0.0       0.0       0.0  \n",
       "BSU24250       1.0       0.0       0.0  \n",
       "BSU36020       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = intersect(tfs, genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove self-interactions from list of potential interactions\n",
    "temp_values = pp.ix[predictors,predictors].values\n",
    "np.fill_diagonal(temp_values, 0)\n",
    "pp.ix[predictors,predictors] = temp_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BBSR_per_gene(idx, X, Y, pp, weights, ns):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ppi = pp.ix[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ppi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
