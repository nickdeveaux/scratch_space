{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferelator.R ported to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas\n",
    "from scipy.stats import nbinom\n",
    "import seaborn\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proc_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-15\n"
     ]
    }
   ],
   "source": [
    "print proc_time.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PARS['input.dir'] = 'input/bsubtilis'\n",
    "PARS['exp.mat.file'] = 'expression.tsv'\n",
    "PARS['tf.names.file'] = 'tf_names.tsv'\n",
    "PARS['meta.data.file'] = 'meta_data.tsv'\n",
    "PARS['priors.file'] = None # 'gold_standard.tsv'\n",
    "PARS['gold.standard.file'] = 'gold_standard.tsv'\n",
    "PARS['leave.out.file'] = None\n",
    "PARS['randomize.expression'] = False\n",
    "PARS['job.seed'] = 42  # set to None if a random seed should be used\n",
    "PARS['save.to.dir'] = None\n",
    "PARS['num.boots'] = 20\n",
    "PARS['max.preds'] = 10\n",
    "PARS['mi.bins'] = 10\n",
    "PARS['cores'] = 8\n",
    "PARS['delT.max'] = 110\n",
    "PARS['delT.min'] = 0\n",
    "PARS['tau'] = 45\n",
    "\n",
    "# I've modified these parameters to make them lists\n",
    "PARS['perc.tp'] = [0]\n",
    "PARS['perm.tp'] = [1]\n",
    "PARS['perc.fp'] = [0]\n",
    "PARS['perm.fp'] = [1]\n",
    "PARS['pr.sel.mode'] = 'random'  # prior selection mode: 'random' or 'tf'\n",
    "PARS['eval.on.subset'] = False\n",
    "PARS['method'] = 'BBSR'  # 'BBSR' or 'MEN'\n",
    "PARS['prior.weight'] = 1\n",
    "PARS['use.tfa'] = False\n",
    "PARS['prior.ss'] = False\n",
    "PARS['output.summary'] = False\n",
    "PARS['output.report'] = False\n",
    "PARS['output.tf.plots'] = False\n",
    "# so['e of the elastic net parameters that are essentially constants;\n",
    "# on['y override in config script if you know what you are doing\n",
    "PARS['enet.sparseModels'] = True    # sparser models\n",
    "PARS['enet.nCv'] = 10               # number of cross-validations\n",
    "PARS['enet.lambda'] = [0, 1, 100]  # l2 weights\n",
    "PARS['enet.verbose'] = False        # print progress to screen\n",
    "PARS['enet.plot.it'] = False        # generate cross-validation plots\n",
    "PARS['enet.plot.file.name'] = None  # file name for plots\n",
    "PARS['method'] = 'BBSR'  # which method to use; either 'MEN' or 'BBSR'\n",
    "PARS['prior.weight'] = 1  # the weight for the priors; has to be larger than 1\n",
    "# fo[' priors to have an effect\n",
    "PARS['output.summary'] = True  # write a summary tsv and RData file of network\n",
    "PARS['output.report'] = True  # create html network report\n",
    "PARS['output.tf.plots'] = True  # create png files with plots of TFs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding variable to point to top level\n",
    "PARS['top.level.dir'] = '/Users/ndeveaux/Dev/Inferelator/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trivial_meta_data(column_names):\n",
    "    meta_data = pandas.DataFrame({'condName': column_names})\n",
    "    meta_data['isTs'] = False\n",
    "    meta_data['is1stLast'] = 'e'\n",
    "    meta_data['prevCol'] = None\n",
    "    meta_data['del.t'] = None\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I removed the read RData capability from read_input\n",
    "def read_input(input_dir, exp_mat_file, tf_names_file, meta_data_file, \n",
    "                       priors_file, gold_standard_file, leave_out_file, randomize_expression):\n",
    "  IN = {}\n",
    "  \n",
    "  print('Reading input: expression matrix')\n",
    "  IN['exp.mat'] = pandas.read_csv(os.path.join(input_dir, exp_mat_file), header=0, index_col=0, sep='\\t')\n",
    "  \n",
    "  print('Reading TF names')\n",
    "  IN['tf.names'] = list(set(pandas.read_csv(os.path.join(input_dir, tf_names_file), header=None, squeeze=True)))\n",
    "  \n",
    "  IN['tf.with.expr'] = intersect(IN['tf.names'], IN['exp.mat'].index)\n",
    "\n",
    "  print('reading metadata')\n",
    "  if meta_data_file: \n",
    "      IN['meta.data'] = pandas.read_csv(os.path.join(input_dir, meta_data_file), \n",
    "                                 header=0, sep='\\t')    \n",
    "  # no meta data given - assume all steady state measurements\n",
    "  else: \n",
    "      IN['meta.data'] = trivial_meta_data(IN['exp.mat'].columns)\n",
    "\n",
    "  \n",
    "  print('reading leave-out file')\n",
    "  # if there is a leave-out file, ignore some conditions\n",
    "  if leave_out_file:\n",
    "    leave_out = pandas.read_csv(os.path.join(input_dir, leave_out_file), header=None, squeeze=True)\n",
    "    print('Leaving out the following conditions: ' + leave_out)\n",
    "    print '{} of {} are present in the expression data'.format(\n",
    "        len(intersect(leave_out, list(IN['exp.mat'].columns))), len(leave_out))\n",
    "    # TODO implement leaveout\n",
    "  \n",
    "  \n",
    "  print('reading priors matrix')\n",
    "  IN['priors.mat'] = None\n",
    "  if priors_file:\n",
    "    IN['priors.mat'] = pandas.read_csv(os.path.join(input_dir, priors_file), header=0)\n",
    "    \n",
    "    # TODO write the reshape prior function (currently implement in R_scripts/utils.R)\n",
    "    # IN$priors.mat <- reshape.prior(IN$priors.mat, rownames(IN$exp.mat), IN$tf.names)\n",
    "  \n",
    "\n",
    "  print('reading gold standard matrix')\n",
    "  IN['gs.mat'] = None\n",
    "  if gold_standard_file:\n",
    "    IN['gs.mat'] = pandas.read_csv(os.path.join(input_dir, gold_standard_file),\n",
    "                                   header=0, sep='\\t')\n",
    "    # TODO write the reshape prior function (currently implement in R_scripts/utils.R)      \n",
    "    #IN$gs.mat <- reshape.prior(IN$gs.mat, rownames(IN$exp.mat), IN$tf.names)\n",
    "  \n",
    "  print(' ... done.')\n",
    "  \n",
    "  if randomize_expression:\n",
    "    print('randomize_expression is set to TRUE; randomizing expression matrix ...')\n",
    "    old_df = IN['exp.mat']\n",
    "    new_rows = np.random.permutation(IN['exp.mat'].shape[0])\n",
    "    new_cols = np.random.permutation(IN['exp.mat'].shape[1])\n",
    "    for row in range(IN['exp.mat'].shape[0]):\n",
    "        for col in range(IN['exp.mat'].shape[1]):\n",
    "            IN['exp.mat'].ix[row, col] = old_df.ix[new_rows[row], new_cols[col]]\n",
    "    print(' done.\\n')\n",
    "  \n",
    "  return IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # TODO: figure out if this is needed, if not, remove it\n",
    "    # create dummy clusterStack - a real clusterStack is only needed when inferring \n",
    "    # on bi-clusters\n",
    "   # clusterStack <- trivial.cluster.stack(IN$exp.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input: expression matrix\n",
      "Reading TF names\n",
      "reading metadata\n",
      "reading leave-out file\n",
      "reading priors matrix\n",
      "reading gold standard matrix\n",
      " ... done.\n"
     ]
    }
   ],
   "source": [
    "IN = read_input(os.path.join(PARS['top.level.dir'], PARS['input.dir']),PARS['exp.mat.file'], PARS['tf.names.file'], PARS['meta.data.file'], \n",
    "                       PARS['priors.file'], PARS['gold.standard.file'], PARS['leave.out.file'], PARS['randomize.expression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dir: /Users/ndeveaux/Dev/Inferelator/input/bsubtilis/2016-08-15\n"
     ]
    }
   ],
   "source": [
    "if not PARS['save.to.dir']:\n",
    "  PARS['save.to.dir'] = os.path.join(PARS['top.level.dir'], PARS['input.dir'],str(proc_time.date()))\n",
    "print \"Output dir: \" + PARS['save.to.dir']\n",
    "if not os.path.exists(PARS['save.to.dir']):\n",
    "  os.makedirs(PARS['save.to.dir'])\n",
    "elif os.path.exists(os.path.join(PARS['save.to.dir'], \"/params_and_input\")):\n",
    "  print 'The output file {} already exists. Exiting.'.format(os.path.join(PARS['save.to.dir'], \"/params_and_input\"))\n",
    "  # TODO find a way to Exit here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating design and response matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# design matrix is same as exp.mat leaving out last time points\n",
    "# response matrix is same as design for steady state; linear interpolation else\n",
    "def design_and_response(meta_data, exp_mat, delT_min, delT_max, tau):\n",
    "    cond = meta_data['condName']\n",
    "    prev = meta_data['prevCol']\n",
    "    delt = meta_data['del.t'] \n",
    "    \n",
    "    # the following operations (setting a value on a copy of a slice from a DataFrame) are not allowed with pandas\n",
    "    # break time series if del.t is larger than delT.max\n",
    "    # prev[delt > delT.max] <- NA\n",
    "    # delt[delt > delT.max] <- NA\n",
    "    \n",
    "    if set(meta_data['condName']) != set(exp_mat.columns):\n",
    "        print 'There are set differences between cond and exp mat'\n",
    "        \n",
    "        # Check that the condNames and the exp_mat columns are in sync:\n",
    "        mismatched_condNames = meta_data['condName'][meta_data['condName'] != exp_mat.columns]\n",
    "        \n",
    "        # This actually discovered a crucial difference between R data frames and pandas:\n",
    "        # R dataframes allow there to be two columns with the same name, but pandas won't \n",
    "        # Key example: Mt0_1 exists twice in expression data\n",
    "        if len(mismatched_condNames) > 0:\n",
    "            print \"There are rows in expression matrix that don't match metadata\"\n",
    "            print mismatched_condNames\n",
    "            correct_col_names = list(exp_mat.columns[meta_data['condName'] != exp_mat.columns])\n",
    "            print correct_col_names\n",
    "            # These can be set using the loc function:\n",
    "            meta_data['condName'][meta_data['condName'] != exp_mat.columns] = correct_col_names\n",
    "            \n",
    "        mismatched_condNames = meta_data['condName'][meta_data['condName'] != exp_mat.columns]\n",
    "        if len(mismatched_condNames) > 0:\n",
    "            print 'Rewrite Failed'\n",
    "    \n",
    "    if set(meta_data['condName']) != set(exp_mat.columns):\n",
    "        print 'There are still set differences between cond and exp mat'\n",
    "    else:\n",
    "        print 'All good'\n",
    "    \n",
    "    # Handle steady state conditions first\n",
    "    # Steady state is defined as not having a previous state, and not being any other state's previous state\n",
    "    steady = prev.isnull() & (cond.isin(prev) != True)\n",
    "    \n",
    "    # This is a quick fix but should instead use the prev col. \n",
    "    des_matrix = pandas.concat([pandas.DataFrame(exp_mat[cond[steady]]), pandas.DataFrame(exp_mat[cond[steady != True]])], axis = 1)\n",
    "    res_matrix = pandas.DataFrame(des_matrix)\n",
    "    \n",
    "    # This creates a 4218 row by  242 column matrix whose values are columns going from 1... 242\n",
    "    # resp.idx <- t(matrix(1:ncol(res.mat), ncol(res.mat), nrow(exp.mat)))\n",
    "    \n",
    "    # Having run the R code, the only difference I see in the des_matrix from exp_is the ordering. \n",
    "    return des_matrix, res_matrix\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call into R to get design and response matrices. \n",
    "# TODO: figure out why the existing exp_mat.csv is ok with having an offset top header col (seems like it should be fixed)\n",
    "# Additionally, why does it get chopped down to 136 conditions?\n",
    "IN['exp.mat'].to_csv('exp_mat.csv')\n",
    "IN['meta.data'].to_csv('meta_data.csv')\n",
    "subprocess.call(['R', '-f', './design_and_response_driver.R'])\n",
    "final_design = pandas.read_csv('design.tsv', sep='\\t')\n",
    "final_response = pandas.read_csv('response.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# des_matrix, res_matrix = design_and_response(IN['meta.data'], IN['exp.mat'], PARS['delT.min'], \n",
    "                               # PARS['delT.max'], PARS['tau'])\n",
    "des_matrix = final_design\n",
    "res_matrix = final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this function used to be important when we would iterate over the priors matrix and take samples/permutations\n",
    "# But all it does now is return the prior matrix\n",
    "def get_priors(exp_mat, tf_names, priors_mat, gs_mat, eval_on_subset, \n",
    "                      job_seed, perc_tp, perm_tp, perc_fp, perm_fp, sel_mode):\n",
    "    if priors_mat is None:\n",
    "        # Create a zero'd out DataFrame\n",
    "        priors_mat = pandas.DataFrame([[0 for x in range(len(tf_names))] for y in range(len(exp_mat.index))])\n",
    "        priors_mat.columns = tf_names\n",
    "        priors_mat.index = exp_mat.index\n",
    "        \n",
    "        \n",
    "    # priors.pars is list of prior parameters; every entry is a vector of four\n",
    "    # elements: perc.tp, tp permutation number, perc.fp, fp permutation number\n",
    "    priors_parameters = []\n",
    "    \n",
    "    # I tried to implement the length check but it seems silly in python since these aren't even vectors, they're scalars.\n",
    "    \n",
    "    lengths = [len(x) for x in [perc_tp, perm_tp, perc_fp, perm_fp]]\n",
    "    print lengths\n",
    "    if len(set(lengths)) != 1:\n",
    "        print \"\"\"Error parsing prior parameters: perc.tp, perm.tp, perc.fp, perm.fp \\\n",
    "        don't have the same length.\"\"\"\n",
    "        \n",
    "    for i in range(next(iter(set(lengths)))):\n",
    "        # Get the modulo remainder\n",
    "        rmndr = max(perm_tp[i], perm_fp[i]) % min(perm_tp[i], perm_fp[i])\n",
    "        if (rmndr != 0):\n",
    "            print\"\"\"Error parsing prior parameters: Larger number of permutations is \\\n",
    "            not multiple of smaller number.\"\"\"\n",
    "        priors_parameters.append([perc_tp, perm_tp, perc_fp, perm_fp])\n",
    "        \n",
    "    for pp in priors_parameters:\n",
    "        # priors[[i]] <- Matrix(0, nrow(priors.mat), ncol(priors.mat), dimnames=dimnames(priors.mat))\n",
    "        prior_names = 'frac_tp_{}_perm_{}--frac_fp_{}_perm_{}'.format(pp[0], pp[1], pp[2], pp[3])\n",
    "        \n",
    "    # Ignore the hundreds of lines of R code in priors.R\n",
    "    \n",
    "    return priors_mat, prior_names\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "priors_mat, prior_name = get_priors(IN['exp.mat'], IN['tf.names'], IN['priors.mat'], IN['gs.mat'], \n",
    "                       PARS['eval.on.subset'], PARS['job.seed'], PARS['perc.tp'],\n",
    "                       PARS['perm.tp'], PARS['perc.fp'], PARS['perm.fp'], \n",
    "                       PARS['pr.sel.mode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the bootstrap permutations\n",
    "# By sampling with replacement from the num cols of the result matrix\n",
    "col_range = range(len(res_matrix.columns))\n",
    "IN['bs.pi'] = pandas.DataFrame([[random.choice(col_range) for x in col_range] for y in range(PARS['num.boots'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>103</td>\n",
       "      <td>106</td>\n",
       "      <td>133</td>\n",
       "      <td>71</td>\n",
       "      <td>109</td>\n",
       "      <td>67</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>123</td>\n",
       "      <td>66</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>108</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "      <td>35</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>77</td>\n",
       "      <td>99</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>131</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>124</td>\n",
       "      <td>101</td>\n",
       "      <td>106</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>125</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>91</td>\n",
       "      <td>131</td>\n",
       "      <td>93</td>\n",
       "      <td>135</td>\n",
       "      <td>52</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "      <td>47</td>\n",
       "      <td>75</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>110</td>\n",
       "      <td>34</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>124</td>\n",
       "      <td>135</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113</td>\n",
       "      <td>91</td>\n",
       "      <td>22</td>\n",
       "      <td>98</td>\n",
       "      <td>112</td>\n",
       "      <td>113</td>\n",
       "      <td>28</td>\n",
       "      <td>82</td>\n",
       "      <td>52</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>42</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "      <td>134</td>\n",
       "      <td>74</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96</td>\n",
       "      <td>14</td>\n",
       "      <td>109</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>123</td>\n",
       "      <td>127</td>\n",
       "      <td>68</td>\n",
       "      <td>89</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>131</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>25</td>\n",
       "      <td>103</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>108</td>\n",
       "      <td>72</td>\n",
       "      <td>60</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>105</td>\n",
       "      <td>76</td>\n",
       "      <td>132</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>69</td>\n",
       "      <td>39</td>\n",
       "      <td>69</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>73</td>\n",
       "      <td>33</td>\n",
       "      <td>95</td>\n",
       "      <td>116</td>\n",
       "      <td>83</td>\n",
       "      <td>116</td>\n",
       "      <td>27</td>\n",
       "      <td>51</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>21</td>\n",
       "      <td>53</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>69</td>\n",
       "      <td>38</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>104</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "      <td>111</td>\n",
       "      <td>84</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77</td>\n",
       "      <td>115</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "      <td>37</td>\n",
       "      <td>131</td>\n",
       "      <td>125</td>\n",
       "      <td>130</td>\n",
       "      <td>83</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>117</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>69</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>133</td>\n",
       "      <td>38</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>127</td>\n",
       "      <td>53</td>\n",
       "      <td>117</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>116</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>96</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>103</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>113</td>\n",
       "      <td>101</td>\n",
       "      <td>91</td>\n",
       "      <td>27</td>\n",
       "      <td>114</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>87</td>\n",
       "      <td>13</td>\n",
       "      <td>122</td>\n",
       "      <td>117</td>\n",
       "      <td>127</td>\n",
       "      <td>79</td>\n",
       "      <td>86</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>82</td>\n",
       "      <td>64</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>83</td>\n",
       "      <td>121</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>126</td>\n",
       "      <td>46</td>\n",
       "      <td>65</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>110</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>133</td>\n",
       "      <td>64</td>\n",
       "      <td>22</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>61</td>\n",
       "      <td>129</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>134</td>\n",
       "      <td>31</td>\n",
       "      <td>92</td>\n",
       "      <td>113</td>\n",
       "      <td>14</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>82</td>\n",
       "      <td>134</td>\n",
       "      <td>125</td>\n",
       "      <td>97</td>\n",
       "      <td>106</td>\n",
       "      <td>122</td>\n",
       "      <td>6</td>\n",
       "      <td>122</td>\n",
       "      <td>97</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65</td>\n",
       "      <td>52</td>\n",
       "      <td>24</td>\n",
       "      <td>98</td>\n",
       "      <td>91</td>\n",
       "      <td>109</td>\n",
       "      <td>93</td>\n",
       "      <td>132</td>\n",
       "      <td>39</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>125</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>47</td>\n",
       "      <td>90</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>86</td>\n",
       "      <td>129</td>\n",
       "      <td>114</td>\n",
       "      <td>36</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>41</td>\n",
       "      <td>110</td>\n",
       "      <td>45</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "      <td>108</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>105</td>\n",
       "      <td>116</td>\n",
       "      <td>90</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "      <td>54</td>\n",
       "      <td>105</td>\n",
       "      <td>97</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>129</td>\n",
       "      <td>118</td>\n",
       "      <td>65</td>\n",
       "      <td>36</td>\n",
       "      <td>80</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>71</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>68</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>130</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   126  127  128  129  \\\n",
       "0    67  103  106  133   71  109   67   25   73   12 ...   124  135    0   41   \n",
       "1    34   81   79   83   35  127  127   77   99   82 ...   121   66   46  131   \n",
       "2   133   92    7   49   13   65   64   24  125  130 ...   118   91  131   93   \n",
       "3   129   47   75  101    5   34   41  125   70   31 ...    99   97  110   34   \n",
       "4   113   91   22   98  112  113   28   82   52  124 ...     4    5   99   42   \n",
       "5    96   14  109   24   22   31   17   29   64    5 ...    30  128  123  127   \n",
       "6   135    6  113   50   35   24  120   25  103  102 ...    33  108   72   60   \n",
       "7    22   41  112    6   28   36   69   39   69   28 ...    45   73   33   95   \n",
       "8    77   21   53   27   31   69   38   65   57    2 ...    29  104   42   49   \n",
       "9    77  115   15   43   49    2   68   15   60   28 ...   107   93   68   37   \n",
       "10  117   33   62   69   86   97   63  133   38  121 ...    59   65   68   65   \n",
       "11  116   17   42   96   46    5  103   77   93   66 ...    53   52  113  101   \n",
       "12   72   72   87   13  122  117  127   79   86   80 ...    81   80    8   82   \n",
       "13   83  121   88   91   10  101  126   46   65   44 ...    67  110   15   44   \n",
       "14   92    6  126   61  129   12   15   25   69   76 ...    88  134   31   92   \n",
       "15   82  134  125   97  106  122    6  122   97   19 ...   115   31   50   31   \n",
       "16   65   52   24   98   91  109   93  132   39  103 ...    70  125   45   16   \n",
       "17   24   20   86  129  114   36   82   74   12   22 ...    14   20   16    9   \n",
       "18   86   94    8  108  102   20  105  116   90   62 ...    25   56   58   31   \n",
       "19  129  118   65   36   80   13   10   22  122   76 ...    96   71   85   73   \n",
       "\n",
       "    130  131  132  133  134  135  \n",
       "0   123   66   37   43  108  134  \n",
       "1     9   16  124  101  106   65  \n",
       "2   135   52   71    3   43   90  \n",
       "3   123    4  110  124  135  115  \n",
       "4    73   78  134   74   95    1  \n",
       "5    68   89  105  106  131   50  \n",
       "6    95   94  105   76  132   85  \n",
       "7   116   83  116   27   51   42  \n",
       "8   111   84   40   50    6   90  \n",
       "9   131  125  130   83  121    1  \n",
       "10    9   45  127   53  117   72  \n",
       "11   91   27  114   65   73   41  \n",
       "12   64   36    6  118   25   45  \n",
       "13  110    6  133   64   22   96  \n",
       "14  113   14   86   17   39  128  \n",
       "15   53   32   65   22   75    6  \n",
       "16  100   47   90   21    6  134  \n",
       "17   40   78   41  110   45   64  \n",
       "18   54  105   97   12   41   39  \n",
       "19   68   40   12   35  130   71  \n",
       "\n",
       "[20 rows x 136 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN['bs.pi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFA specific initialization\n",
    "Skipping for now, since use TFA set to false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "des_matrix = des_matrix.ix[ IN['tf.with.expr'] , :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas = []\n",
    "betas_resc  = []\n",
    "bins = PARS['mi.bins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(IN['bs.pi'])):\n",
    "    X = des_matrix.ix[:, IN['bs.pi'].ix[i,:]]\n",
    "    Y = res_matrix.ix[:, IN['bs.pi'].ix[i,:]]\n",
    "    X.to_csv('X.csv')\n",
    "    Y.to_csv('Y.csv')\n",
    "    priors_mat.to_csv('priors_mat.csv')\n",
    "    subprocess.call(['R', '-f', './mi_clr_driver.R'])\n",
    "    clr_matrix = pandas.read_csv('clr_matrix.tsv', sep='\\t')\n",
    "    clr_matrix = clr_matrix.ix[:, IN['tf.names']]\n",
    "    clr_matrix.to_csv('clr_matrix.csv')\n",
    "    subprocess.call(['R', '-f', './BBSR_driver.R'])\n",
    "    betas.append(pandas.read_csv('betas.tsv', sep='\\t'))\n",
    "    betas_resc.append(pandas.read_csv('betas_rescaled.tsv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Combine confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_confidences = pandas.DataFrame(np.zeros((betas[0].shape)), index = betas[0].index, columns = betas[0].columns )\n",
    "len(set(list(betas[9].columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for beta_resc in betas_resc:\n",
    "    # this ranking code is especially wordy because the rank function only works in one dimension (col or row), so I had to flatten the matrix\n",
    "    ranked_df =np.reshape(pandas.DataFrame(np.ndarray.flatten(beta_resc.values)).rank( method = \"average\").values, betas_resc[0].shape)\n",
    "    combined_confidences = combined_confidences + ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_element = min(combined_confidences.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_confidences = (combined_confidences - min_element) / (PARS['num.boots'] * combined_confidences.size - min_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999944192585275"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(combined_confidences.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSU31410</th>\n",
       "      <th>BSU29740</th>\n",
       "      <th>BSU27890</th>\n",
       "      <th>BSU40800</th>\n",
       "      <th>BSU37650</th>\n",
       "      <th>BSU05370</th>\n",
       "      <th>BSU21780</th>\n",
       "      <th>BSU05700</th>\n",
       "      <th>BSU39430</th>\n",
       "      <th>BSU02970</th>\n",
       "      <th>...</th>\n",
       "      <th>BSU02370</th>\n",
       "      <th>BSU12560</th>\n",
       "      <th>BSU24020</th>\n",
       "      <th>BSU07220</th>\n",
       "      <th>BSU15320</th>\n",
       "      <th>BSU29400</th>\n",
       "      <th>BSU27170</th>\n",
       "      <th>BSU09520</th>\n",
       "      <th>BSU25490</th>\n",
       "      <th>BSU17850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSU00370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU08100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU01810</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU24250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU36020</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BSU31410  BSU29740  BSU27890  BSU40800  BSU37650  BSU05370  \\\n",
       "BSU00370       0.0       0.0       0.0       0.0       0.0  0.049497   \n",
       "BSU08100       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "BSU01810       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "BSU24250       0.0       0.0       0.0       0.0       0.0  0.049625   \n",
       "BSU36020       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "\n",
       "          BSU21780  BSU05700  BSU39430  BSU02970    ...     BSU02370  \\\n",
       "BSU00370       0.0       0.0       0.0       0.0    ...     0.049840   \n",
       "BSU08100       0.0       0.0       0.0       0.0    ...     0.000000   \n",
       "BSU01810       0.0       0.0       0.0       0.0    ...     0.000000   \n",
       "BSU24250       0.0       0.0       0.0       0.0    ...     0.199176   \n",
       "BSU36020       0.0       0.0       0.0       0.0    ...     0.000000   \n",
       "\n",
       "          BSU12560  BSU24020  BSU07220  BSU15320  BSU29400  BSU27170  \\\n",
       "BSU00370       0.0       0.0       0.0       0.0  0.000000       0.0   \n",
       "BSU08100       0.0       0.0       0.0       0.0  0.049580       0.0   \n",
       "BSU01810       0.0       0.0       0.0       0.0  0.000000       0.0   \n",
       "BSU24250       0.0       0.0       0.0       0.0  0.049357       0.0   \n",
       "BSU36020       0.0       0.0       0.0       0.0  0.099230       0.0   \n",
       "\n",
       "          BSU09520  BSU25490  BSU17850  \n",
       "BSU00370       0.0       0.0       0.0  \n",
       "BSU08100       0.0       0.0       0.0  \n",
       "BSU01810       0.0       0.0       0.0  \n",
       "BSU24250       0.0       0.0       0.0  \n",
       "BSU36020       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_confidences.to_csv('combined_confidences.csv')\n",
    "combined_confidences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold and Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "th = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_sign = pandas.DataFrame(np.zeros((betas[0].shape)), index = betas[0].index, columns = betas[0].columns )\n",
    "betas_non_zero = pandas.DataFrame(np.zeros((betas[0].shape)), index = betas[0].index, columns = betas[0].columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    1, ..., 4216, 4216, 4216]),\n",
       " array([ 30, 172, 139, ...,   7, 128, 236]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(betas[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for beta in betas:\n",
    "    betas_sign = betas_sign + np.sign(beta.values)\n",
    "    betas_non_zero = betas_non_zero + np.absolute(np.sign(beta.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we only care about interactions that are present in more than th (fraction) bootstraps\n",
    "ind_vec = np.where( betas_non_zero > len(betas) * th)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas_stack = np.stack([b.values[ind_vec] for b in betas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas_mean = np.mean(betas_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_median = np.median(betas_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_min = np.min(betas_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_max = np.max(betas_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas_resc_stack = np.stack([b.values[ind_vec] for b in betas_resc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas_resc_mean = np.mean(betas_resc_stack, axis = 0)\n",
    "betas_resc_median = np.median(betas_resc_stack, axis = 0)\n",
    "betas_resc_min = np.min(betas_resc_stack, axis = 0)\n",
    "betas_resc_max = np.max(betas_resc_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUPR calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates = np.where( combined_confidences > 0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For some reason there are more target genes in the gold standard than we've gotten from the exp matrix\n",
    "# Filter it\n",
    "gold_standard_filtered = IN['gs.mat'].loc[combined_confidences.index]\n",
    "gold_standard_filtered = gold_standard_filtered[combined_confidences.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "condition_positive = len(np.where(gold_standard_filtered.values > 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rank from highest to lowest confidence\n",
    "sorted_candidates = np.argsort(combined_confidences.values[candidates], axis = None)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999944192585275"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_confidences.values[candidates][sorted_candidates[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_values = np.array(gold_standard_filtered.values[candidates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_values[sorted_candidates[0:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = 0.0\n",
    "FP = 0.0\n",
    "precision = []\n",
    "recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in sorted_candidates:\n",
    "    truth = gs_values[i]\n",
    "    if truth == 1:\n",
    "        TP = TP + 1\n",
    "    else:\n",
    "        FP = FP + 1\n",
    "    precision.append(TP / (TP + FP))\n",
    "    recall.append(TP / condition_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11f7f29d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFkCAYAAABW9YMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10509c9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recall, precision)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4218, 239)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_confidences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1004958\n",
       "1       3144\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.value_counts(np.ndarray.flatten(gold_standard_filtered.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSU31410</th>\n",
       "      <th>BSU29740</th>\n",
       "      <th>BSU27890</th>\n",
       "      <th>BSU40800</th>\n",
       "      <th>BSU37650</th>\n",
       "      <th>BSU05370</th>\n",
       "      <th>BSU21780</th>\n",
       "      <th>BSU05700</th>\n",
       "      <th>BSU39430</th>\n",
       "      <th>BSU02970</th>\n",
       "      <th>...</th>\n",
       "      <th>BSU02370</th>\n",
       "      <th>BSU12560</th>\n",
       "      <th>BSU24020</th>\n",
       "      <th>BSU07220</th>\n",
       "      <th>BSU15320</th>\n",
       "      <th>BSU29400</th>\n",
       "      <th>BSU27170</th>\n",
       "      <th>BSU09520</th>\n",
       "      <th>BSU25490</th>\n",
       "      <th>BSU17850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSU00370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU08100</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU01810</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU24250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU36020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BSU31410  BSU29740  BSU27890  BSU40800  BSU37650  BSU05370  \\\n",
       "BSU00370         0         0         0         0         0         0   \n",
       "BSU08100         0         1         0         0         0         0   \n",
       "BSU01810         0         0         0         0         0         0   \n",
       "BSU24250         0         0         0         0         0         0   \n",
       "BSU36020         0         0         0         0         0         0   \n",
       "\n",
       "          BSU21780  BSU05700  BSU39430  BSU02970    ...     BSU02370  \\\n",
       "BSU00370         0         0         0         0    ...            0   \n",
       "BSU08100         0         0         0         0    ...            0   \n",
       "BSU01810         0         0         0         0    ...            0   \n",
       "BSU24250         0         0         0         0    ...            0   \n",
       "BSU36020         0         0         0         0    ...            0   \n",
       "\n",
       "          BSU12560  BSU24020  BSU07220  BSU15320  BSU29400  BSU27170  \\\n",
       "BSU00370         0         0         0         0         0         0   \n",
       "BSU08100         0         0         0         0         0         0   \n",
       "BSU01810         0         0         0         0         0         0   \n",
       "BSU24250         0         0         0         0         0         0   \n",
       "BSU36020         0         0         0         0         0         0   \n",
       "\n",
       "          BSU09520  BSU25490  BSU17850  \n",
       "BSU00370         0         0         0  \n",
       "BSU08100         0         0         0  \n",
       "BSU01810         0         0         0  \n",
       "BSU24250         0         0         0  \n",
       "BSU36020         0         0         0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_standard_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quick way to double check distribution of values\n",
    "# pandas.value_counts(np.ndarray.flatten(combined_confidences.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1085.6681035581576"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(betas_resc[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "argsorted = np.argsort(betas_resc[1].values, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([671074, 671075, 671076, ..., 670074, 670075, 670076])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argsorted[1:3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step one of loop\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas.append(pandas.read_csv('betas.tsv', sep='\\t'))\n",
    "betas_resc.append(pandas.read_csv('betas_rescaled.tsv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set a random sample of the edges to zero\n",
    "# only need to do this if we have priors\n",
    "\n",
    "# group predictors just returns the design matrix, res and prior matrix if it finds no groups:\n",
    "# if no TF was excluded and no TFs were grouped, it returns the des, res, and prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_predictors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = des_matrix.ix[:, IN['bs.pi'].ix[i,:]]\n",
    "Y = res_matrix.ix[:, IN['bs.pi'].ix[i,:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder on mutual information:\n",
    "<img src=\"files/olah_mi.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Short example\n",
    "x = X.ix[200,:]\n",
    "y = Y.ix[200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H, xedges, yedges = np.histogram2d(x,y,bins)\n",
    "plt.set_cmap('viridis')\n",
    "im = plt.imshow(H, interpolation='none', \n",
    "                extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an inefficient implementation of calc_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shannon_entropy(p):\n",
    "    # Since p represents a discrete prob dist, check for floating point approximation to 1.0\n",
    "    if not np.allclose(sum(p), 1.0): \n",
    "        raise Exception('Probabilities input to shannon entropy need to sum to 1')\n",
    "    return - sum([x * np.log(x) for x in p if x != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_mi(x, y, bins):\n",
    "    hist, scale  = np.histogram(x, bins)\n",
    "    x_p = hist / float(sum(hist))\n",
    "    hist, scale = np.histogram(y, bins)\n",
    "    y_p = hist / float(sum(hist))\n",
    "    H, xscale, yscale = np.histogram2d(x ,y, bins)\n",
    "    joint_p = (H / float(sum(sum(H)))).flatten()\n",
    "    return (shannon_entropy(y_p) + shannon_entropy(x_p)) - shannon_entropy(joint_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFVCAYAAAA+OJwpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngAEEGQAAAwgyAAAGEGQAAAz4P4HTN88VsKfMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119f7a210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins = np.histogram(X.ix[10,:],bins)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25764680571550524"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mi(X.ix[100,:], Y.ix[100,:], PARS['mi.bins'])\n",
    "# mi_matrix = [[calc_mi(X.ix[i,:], Y.ix[j,:], PARS['mi.bins']) for i in range(X.shape[0])] for j in range(Y.shape[0])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(X.index) > 6000:\n",
    "    # speeds up MI calculation for large datasets\n",
    "    # I actually don't know what this does, since X's rows are already filtered by 'tf.with.expr', \n",
    "    # which itself if a subset of IN['tf.names']\n",
    "    X = X.ix[group_predictors['tf_names'], :] # This turn X into a TFs x Samples matrix, which is what I expected it to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist, scale  = np.histogram(x, bins)\n",
    "x_p = hist / float(sum(hist))\n",
    "hist, scale = np.histogram(y, bins)\n",
    "y_p = hist / float(sum(hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optionally investigate sklearn.metrics.mutual_info_score(x_p, x_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call into R to calculate tlCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('X.csv')\n",
    "Y.to_csv('Y.csv')\n",
    "priors_mat.to_csv('priors_mat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(['R', '--slave', '-f', './mi_clr_driver.R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clr_matrix = pandas.read_csv('clr_matrix.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter by tf names (this doesn't do anything in the case of B Subtilus, and should filter by group predictions)\n",
    "clr_matrix = clr_matrix.ix[:, IN['tf.names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clr_matrix.to_csv('clr_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(['R', '--slave', '-f', './BBSR_driver.R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSU31410</th>\n",
       "      <th>BSU29740</th>\n",
       "      <th>BSU27890</th>\n",
       "      <th>BSU40800</th>\n",
       "      <th>BSU37650</th>\n",
       "      <th>BSU05370</th>\n",
       "      <th>BSU21780</th>\n",
       "      <th>BSU05700</th>\n",
       "      <th>BSU39430</th>\n",
       "      <th>BSU02970</th>\n",
       "      <th>...</th>\n",
       "      <th>BSU02370</th>\n",
       "      <th>BSU12560</th>\n",
       "      <th>BSU24020</th>\n",
       "      <th>BSU07220</th>\n",
       "      <th>BSU15320</th>\n",
       "      <th>BSU29400</th>\n",
       "      <th>BSU27170</th>\n",
       "      <th>BSU09520</th>\n",
       "      <th>BSU25490</th>\n",
       "      <th>BSU17850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSU00370</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.331829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053941</td>\n",
       "      <td>0.546521</td>\n",
       "      <td>0.247536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474254</td>\n",
       "      <td>0.102544</td>\n",
       "      <td>0.287538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632939</td>\n",
       "      <td>1.041414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.074986</td>\n",
       "      <td>0.241752</td>\n",
       "      <td>0.064521</td>\n",
       "      <td>0.616567</td>\n",
       "      <td>0.130521</td>\n",
       "      <td>0.762131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU08100</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.581412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.918470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319477</td>\n",
       "      <td>0.844766</td>\n",
       "      <td>0.302097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.581768</td>\n",
       "      <td>1.259320</td>\n",
       "      <td>0.222817</td>\n",
       "      <td>0.237525</td>\n",
       "      <td>0.268205</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU01810</th>\n",
       "      <td>1.155553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.493640</td>\n",
       "      <td>0.152953</td>\n",
       "      <td>0.082841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443350</td>\n",
       "      <td>1.578638</td>\n",
       "      <td>1.188237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.253709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU24250</th>\n",
       "      <td>0.917109</td>\n",
       "      <td>2.060313</td>\n",
       "      <td>1.182781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.165756</td>\n",
       "      <td>0.970381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.788951</td>\n",
       "      <td>0.424076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.110401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.698148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017698</td>\n",
       "      <td>1.078584</td>\n",
       "      <td>3.825155</td>\n",
       "      <td>1.904571</td>\n",
       "      <td>0.706518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU36020</th>\n",
       "      <td>0.770376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.016767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458314</td>\n",
       "      <td>0.040748</td>\n",
       "      <td>1.104357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811787</td>\n",
       "      <td>0.290950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626139</td>\n",
       "      <td>1.087694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BSU31410  BSU29740  BSU27890  BSU40800  BSU37650  BSU05370  \\\n",
       "BSU00370  0.000000  1.331829  0.000000  0.053941  0.546521  0.247536   \n",
       "BSU08100  0.000000  0.000000  0.581412  0.000000  0.000000  0.000000   \n",
       "BSU01810  1.155553  0.000000  0.000000  1.493640  0.152953  0.082841   \n",
       "BSU24250  0.917109  2.060313  1.182781  0.000000  1.165756  0.970381   \n",
       "BSU36020  0.770376  0.000000  1.016767  0.000000  0.000000  0.000000   \n",
       "\n",
       "          BSU21780  BSU05700  BSU39430  BSU02970    ...     BSU02370  \\\n",
       "BSU00370       0.0  0.474254  0.102544  0.287538    ...     0.632939   \n",
       "BSU08100       0.0  0.000000  0.000000  0.918470    ...     0.319477   \n",
       "BSU01810       0.0  0.218325  0.000000  0.357855    ...     0.443350   \n",
       "BSU24250       0.0  1.788951  0.424076  0.000000    ...     2.110401   \n",
       "BSU36020       0.0  0.458314  0.040748  1.104357    ...     0.118278   \n",
       "\n",
       "          BSU12560  BSU24020  BSU07220  BSU15320  BSU29400  BSU27170  \\\n",
       "BSU00370  1.041414  0.000000  0.000000  1.074986  0.241752  0.064521   \n",
       "BSU08100  0.844766  0.302097  0.000000  1.581768  1.259320  0.222817   \n",
       "BSU01810  1.578638  1.188237  0.000000  1.253709  0.000000  0.000000   \n",
       "BSU24250  0.000000  0.000000  0.698148  0.000000  0.017698  1.078584   \n",
       "BSU36020  0.000000  0.000000  0.000000  0.000000  0.811787  0.290950   \n",
       "\n",
       "          BSU09520  BSU25490  BSU17850  \n",
       "BSU00370  0.616567  0.130521  0.762131  \n",
       "BSU08100  0.237525  0.268205  0.000000  \n",
       "BSU01810  0.043018  0.000000  0.309516  \n",
       "BSU24250  3.825155  1.904571  0.706518  \n",
       "BSU36020  0.000000  0.626139  1.087694  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_matrix.ix[:, IN['tf.names']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ignore priors for now: priors_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Enter BBSR\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  # Scale and permute design and response matrix\n",
    "X_scaled = pandas.DataFrame(preprocessing.scale(X, axis = 1), index = X.index, columns = X.columns)\n",
    "Y_scaled = pandas.DataFrame(preprocessing.scale(Y, axis = 1), index = Y.index, columns = Y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = Y.shape[0]  # number of genes\n",
    "genes = list(Y.index)\n",
    "K = X.shape[0]  # max number of possible predictors (number of TFs)\n",
    "tfs = list(X.index)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000004"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check that the scaling made each row's std deviations set to 1\n",
    "np.std(X_scaled.ix[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictors that will be used in the regression\n",
    "pp = pandas.DataFrame(np.zeros((G, K)), index = genes, columns = tfs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get top highest indices per row in clr_matrix, store as top_sorted object\n",
    "top_sorted = np.argsort(clr_matrix, axis = 1).ix[:, K - PARS['max.preds']: K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each gene, add the top nS predictors of the list to possible predictors\n",
    "for i in range(G):\n",
    "    pp.ix[i, top_sorted.ix[i, :]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    965922\n",
       "1.0     42180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this point, we expect the values of 1s to be equal to the number of Genes x PARS['max.preds'] (Which should be 10)\n",
    "pandas.value_counts(np.ndarray.flatten(pp.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSU31410</th>\n",
       "      <th>BSU29740</th>\n",
       "      <th>BSU27890</th>\n",
       "      <th>BSU40800</th>\n",
       "      <th>BSU37650</th>\n",
       "      <th>BSU05370</th>\n",
       "      <th>BSU21780</th>\n",
       "      <th>BSU05700</th>\n",
       "      <th>BSU39430</th>\n",
       "      <th>BSU02970</th>\n",
       "      <th>...</th>\n",
       "      <th>BSU02370</th>\n",
       "      <th>BSU12560</th>\n",
       "      <th>BSU24020</th>\n",
       "      <th>BSU07220</th>\n",
       "      <th>BSU15320</th>\n",
       "      <th>BSU29400</th>\n",
       "      <th>BSU27170</th>\n",
       "      <th>BSU09520</th>\n",
       "      <th>BSU25490</th>\n",
       "      <th>BSU17850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSU00370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU08100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU01810</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU24250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSU36020</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BSU31410  BSU29740  BSU27890  BSU40800  BSU37650  BSU05370  \\\n",
       "BSU00370       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU08100       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU01810       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU24250       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU36020       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "          BSU21780  BSU05700  BSU39430  BSU02970    ...     BSU02370  \\\n",
       "BSU00370       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "BSU08100       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "BSU01810       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "BSU24250       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "BSU36020       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "\n",
       "          BSU12560  BSU24020  BSU07220  BSU15320  BSU29400  BSU27170  \\\n",
       "BSU00370       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU08100       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU01810       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU24250       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "BSU36020       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "          BSU09520  BSU25490  BSU17850  \n",
       "BSU00370       0.0       0.0       0.0  \n",
       "BSU08100       0.0       0.0       0.0  \n",
       "BSU01810       0.0       0.0       0.0  \n",
       "BSU24250       1.0       0.0       0.0  \n",
       "BSU36020       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = intersect(tfs, genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove self-interactions from list of potential interactions\n",
    "temp_values = pp.ix[predictors,predictors].values\n",
    "np.fill_diagonal(temp_values, 0)\n",
    "pp.ix[predictors,predictors] = temp_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BBSR_per_gene(idx, X, Y, pp, weights, ns):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ppi = pp.ix[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ppi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
